{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "from sklearn.datasets import make_circles\n",
    "%pylab inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from StringIO import StringIO\n",
    "import pydot_ng\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_table('E:\\DataAnalytics_programming\\Class Notes\\sample exam\\Santa.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "dict_alltweets = [[] for x in xrange(0,df.shape[0])] # creating a list of lists with number of tweets\n",
    "for j in range(0,df.shape[0]):                       # for every tweet\n",
    "    df_sp =df.ix[j,0].split()                        # split the words by spaces\n",
    "\n",
    "    temp_list =[]\n",
    "    list_new=[]\n",
    "    for i in range(0,len(df_sp)):                    # for every word in the list\n",
    "        if len(df_sp)>=i+3:                          # if the combination of 3 exists\n",
    "            temp_list  = df_sp[i:i+3]                # slice the three words from the list of words\n",
    "            list_new.append(\" \".join(temp_list))     # merge them into a single phrase\n",
    "            list_new=list(Series(list_new).unique()) # Take out unique phrases and save as list\n",
    "    dict_alltweets[j] = list_new                     #Save list of phrases in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet 3 is a near-duplicate of a previously seen tweet from the file of tweet 1\n",
      "tweet 4 is a near-duplicate of a previously seen tweet from the file of tweet 2\n",
      "tweet 5 is a near-duplicate of a previously seen tweet from the file of tweet 2\n",
      "tweet 5 is a near-duplicate of a previously seen tweet from the file of tweet 4\n"
     ]
    }
   ],
   "source": [
    "for  i  in range(0,len(dict_alltweets)):             # for every tweet\n",
    "    list1 = dict_alltweets[i]                        # initialize list1\n",
    "    for j in range(0,len(dict_alltweets)):           # for every tweet\n",
    "        if j > i:                                    # if tweet j is after tweet i \n",
    "            list2 = dict_alltweets[j]                # intialize list2\n",
    "            matches=0                                # initialize matches\n",
    "            n1= len(list1)                           # Find lengths of two lists (number of phrases)\n",
    "            n2=len(list2)                            # iterate over two lists and find common matches of phrases\n",
    "            for u in range(0,len(list1)):\n",
    "                for v in range(0,len(list2)):\n",
    "                    if list1[u]==list2[v] and list1!= list2: # len(set(list1) & set(list2))\n",
    "                        matches+=1 \n",
    "            if (float(matches/np.sqrt(n1*n2))>0.5):  # if the cosine comes out to be > 0.5, print else do nothing\n",
    "                print \"tweet \"+ str(j+1)+' is a near-duplicate of a previously seen tweet from the file of tweet '+str(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "set(['Santa Claus Is', 'Claus Is Coming', 'Rt si te', 'si te gusta', 'gusta Santa Claus', 'Is Coming To', 'Town #MTVHottest Justin', 'te gusta Santa', '#MTVHottest Justin Bieber', 'Coming To Town', 'To Town #MTVHottest'])\n"
     ]
    }
   ],
   "source": [
    "print len(set(list1) & set(list2))\n",
    "print set(list1) & set(list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>class</th>\n",
       "      <th>class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://1024kbytes.com</td>\n",
       "      <td>broken</td>\n",
       "      <td>broken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://18x.fr</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://1ting.com</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://3dmgame.com</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://3xupdate.com</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://6ano.org</td>\n",
       "      <td>broken</td>\n",
       "      <td>broken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://7-win.ru</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://7dl.biz</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http://7elm3aber.com</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     url   class  class2\n",
       "0  http://1024kbytes.com  broken  broken\n",
       "1          http://18x.fr     yes     yes\n",
       "2       http://1ting.com     yes     yes\n",
       "3     http://3dmgame.com     yes     yes\n",
       "4    http://3xupdate.com     yes     yes\n",
       "5        http://6ano.org  broken  broken\n",
       "6        http://7-win.ru     yes     yes\n",
       "7         http://7dl.biz     yes     yes\n",
       "8   http://7elm3aber.com     yes     yes"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_table('E:\\DataAnalytics_programming\\Class Notes\\sample exam\\labels.txt', header=None,names=['rater','url','class'])\n",
    "gold = pd.read_table('E:\\DataAnalytics_programming\\Class Notes\\sample exam\\gold.txt', header=None,names=['url','class'])\n",
    "gold1 = gold \n",
    "#appending rows\n",
    "gold1.append(pd.DataFrame(gold['class']))\n",
    "#apepnding columns \n",
    "gold1['class2'] = gold['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged = pd.merge(labels, gold, on='url',how='inner',suffixes=['labels','gold']) \n",
    "New_Data = DataFrame(data=merged.groupby(by='rater')['classgold'].count().sort_values(ascending=False))\n",
    "New_Data.rename(columns={'classgold' : 'count'}, inplace=True)\n",
    "\n",
    "# DataFrame.merge(Series Name) : used to append column to a Dataset\n",
    "# merged['match'] = np.where(merged['classlabels']==merged['classgold'],1,0)  # create flag for a match or not\n",
    "merged.ix[merged['classlabels']== merged['classgold'],'match']=1\n",
    "merged.ix[merged['classlabels']!= merged['classgold'],'match']=0\n",
    "\n",
    "New_Data['match']  = merged.groupby(by='rater')['match'].sum().fillna(0)      # find sum of matches for every rater\n",
    "New_Data['rater']  = New_Data.index.values\n",
    "New_Data['believability']  = (New_Data['match']+1.0)/(New_Data['count']+2.0)  \n",
    "New_Data['believability_ratio']  = (New_Data['believability'])/(1.0- New_Data['believability'])\n",
    "\n",
    "new_merged  = pd.merge(merged, New_Data, on = 'rater',how='left')            # To have the urls also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            rater            url classlabels classgold  match\n",
      "0         atiqnur  http://18x.fr         yes       yes      1\n",
      "1           maria  http://18x.fr         yes       yes      1\n",
      "2  a3kvu2c809dok5  http://18x.fr          no       yes      0\n"
     ]
    }
   ],
   "source": [
    "merged['match'] = np.where(merged['classlabels']==merged['classgold'],1,0)\n",
    "print merged[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Url_Data= DataFrame(new_merged.groupby(by=['url','classlabels'])['believability_ratio'].prod().fillna(0).unstack('classlabels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url\n",
       "http://1024kbytes.com       yes\n",
       "http://18x.fr               yes\n",
       "http://1ting.com            yes\n",
       "http://3dmgame.com          yes\n",
       "http://3xupdate.com         yes\n",
       "http://6ano.org          broken\n",
       "http://7-win.ru             yes\n",
       "http://7dl.biz              yes\n",
       "http://7elm3aber.com        yes\n",
       "dtype: object"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Url_Data.T.idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>match</th>\n",
       "      <th>rater</th>\n",
       "      <th>believability</th>\n",
       "      <th>believability_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rater</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a3kvu2c809dok5</th>\n",
       "      <td>18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>a3kvu2c809dok5</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apul86331somr</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>apul86331somr</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2ufd1i8zo1v4g</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a2ufd1i8zo1v4g</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atiqnur</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>atiqnur</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2gng3wn85say6</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a2gng3wn85say6</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maria</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>maria</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a182jw8u6po60u</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a182jw8u6po60u</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a3ux2fxa3nmjcs</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a3ux2fxa3nmjcs</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a3rlcgrxa34gc0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a3rlcgrxa34gc0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a34m93njc830dp</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a34m93njc830dp</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count  match           rater  believability  \\\n",
       "rater                                                         \n",
       "a3kvu2c809dok5     18   13.0  a3kvu2c809dok5       0.700000   \n",
       "apul86331somr       7    0.0   apul86331somr       0.111111   \n",
       "a2ufd1i8zo1v4g      7    2.0  a2ufd1i8zo1v4g       0.333333   \n",
       "atiqnur             5    2.0         atiqnur       0.428571   \n",
       "a2gng3wn85say6      5    2.0  a2gng3wn85say6       0.428571   \n",
       "maria               4    3.0           maria       0.666667   \n",
       "a182jw8u6po60u      2    0.0  a182jw8u6po60u       0.250000   \n",
       "a3ux2fxa3nmjcs      1    0.0  a3ux2fxa3nmjcs       0.333333   \n",
       "a3rlcgrxa34gc0      1    0.0  a3rlcgrxa34gc0       0.333333   \n",
       "a34m93njc830dp      1    1.0  a34m93njc830dp       0.666667   \n",
       "\n",
       "                believability_ratio  \n",
       "rater                                \n",
       "a3kvu2c809dok5             2.333333  \n",
       "apul86331somr              0.125000  \n",
       "a2ufd1i8zo1v4g             0.500000  \n",
       "atiqnur                    0.750000  \n",
       "a2gng3wn85say6             0.750000  \n",
       "maria                      2.000000  \n",
       "a182jw8u6po60u             0.333333  \n",
       "a3ux2fxa3nmjcs             0.500000  \n",
       "a3rlcgrxa34gc0             0.500000  \n",
       "a34m93njc830dp             2.000000  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "      <td>Not OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "      <td>Not OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "      <td>Not OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety  class  target\n",
       "0  vhigh  vhigh     2       2    small    low  unacc  Not OK\n",
       "1  vhigh  vhigh     2       2    small    med  unacc  Not OK\n",
       "2  vhigh  vhigh     2       2    small   high  unacc  Not OK"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = pd.read_csv('E:\\DataAnalytics_programming\\Class Notes\\sample exam\\cars.csv')\n",
    "cars.ix[cars['class']=='unacc','target'] =\"Not OK\"\n",
    "cars.ix[cars['class']!='unacc','target'] =\"OK\"\n",
    "cars[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety',\n",
       "       'class', 'target'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def entropy_func(df,column_name,yes):                      # 'Yes' is to print out the Predict OK/Not OK for min_var\n",
    "    unique_vals = df[column_name].unique()\n",
    "    Entropy = 0.0\n",
    "    for i in unique_vals:\n",
    "        P= float(df[((df['target']==\"Not OK\") & (df[column_name]==i))].shape[0]) # For a particular column's value, how many P and N\n",
    "        N= float(df[((df['target']==\"OK\") & (df[column_name]==i))].shape[0])\n",
    "        if P==0  or N==0:                                  # Did this to avoid Nans in Entropy\n",
    "            Entropy +=  0.0\n",
    "        else:\n",
    "            Entropy += (-1.0) * ((P* np.log2(P/(P+N))+ N* np.log2(N/(P+N)))) # from Decision Tree presentation in class\n",
    "    \n",
    "        if P==0 and yes == 1: \n",
    "            print column_name, i , \"Predict Not OK\"\n",
    "        elif N==0 and yes == 1: \n",
    "            print column_name, i , \"Predict OK\"    \n",
    "    \n",
    "    return Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lowest_entropy(df,var_list):\n",
    "    min_ent=99999999999999999999999.0\n",
    "    for i in var_list:\n",
    "        if ((min_ent) > entropy_func(df,i,0)): # find the variable with minimum entropy\n",
    "            min_ent = entropy_func(df,i,0)\n",
    "            min_var = i \n",
    "        else: \n",
    "            min_ent = min_ent\n",
    "            min_var = min_var\n",
    "    print min_var, min_ent \n",
    "    print entropy_func(df,min_var,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safety 1127.31060077\n",
      "safety low Predict OK\n",
      "1127.31060077\n"
     ]
    }
   ],
   "source": [
    "lowest_entropy(cars,['maint', 'buying', 'doors', 'persons', 'lug_boot', 'safety']) # All variables except target initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['low', 'med', 'high'], dtype=object)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars['buying'].unique()\n",
    "cars['safety'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# child nodes after first split\n",
    "cars_high = cars[cars['safety']=='high']\n",
    "cars_med = cars[cars['safety']=='med']\n",
    "cars_low = cars[cars['safety']=='low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cars_high:\n",
      "persons 274.876992842\n",
      "persons 2 Predict OK\n",
      "274.876992842\n",
      "None\n",
      "cars_med:\n",
      "persons 283.816053574\n",
      "persons 2 Predict OK\n",
      "283.816053574\n",
      "None\n",
      "cars_low:\n",
      "persons 278.539597379\n",
      "persons 2 Predict OK\n",
      "278.539597379\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# run for each child node and remaining variables to find the next best split\n",
    "\n",
    "print 'cars_high:\\n',lowest_entropy(cars_high, ['maint', 'doors', 'persons', 'lug_boot', 'buying'])\n",
    "print 'cars_med:\\n',lowest_entropy(cars_med, ['maint', 'doors', 'persons', 'lug_boot', 'buying'])\n",
    "print 'cars_low:\\n',lowest_entropy(cars_low, ['maint', 'doors', 'persons', 'lug_boot', 'buying'])\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
